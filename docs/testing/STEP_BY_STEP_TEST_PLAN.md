# ðŸ“‹ STEP BY STEP TEST PLAN - ATP Approval Flow

**Based on**: ATP_PROCESS_APPROVAL_FLOW_IMPLEMENTATION.md
**Date**: 2025-12-28
**Approach**: Incremental testing from bottom-up

---

## ðŸŽ¯ TESTING STRATEGY

### Approach: **Bottom-Up Testing**

`` Layer 1: Backend API Tests (Foundation)
    â†“
 Layer 2: Workflow Engine Tests (Business Logic)
    â†“
 Layer 3: Frontend Component Tests (UI)
    â†“
 Layer 4: End-to-End User Journey Tests (Complete Flow)
```

**Why This Approach?**
- âœ… Test foundation first (backend APIs)
- âœ… Validate business logic before UI
- âœ… Easier to debug failures
- âœ… Can run tests in isolation

---

## ðŸ“Š TESTING SCOPE

### Components to Test (from ATP_PROCESS_APPROVAL_FLOW_IMPLEMENTATION.md)

#### Frontend Components (5)
1. âœ… ATPSubmission.tsx - Document submission interface
2. âœ… ReviewDashboard.tsx - Role-based review dashboard
3. âœ… ApprovalInterface.tsx - Document review and approval
4. âœ… PunchlistManagement.tsx - Issue tracking and rectification
5. âœ… ATPProcessFlow.tsx - Main workflow orchestration

#### Backend Components (2)
1. âœ… Enhanced atpRoutes.js - 7 new API endpoints
2. âœ… atpWorkflowEngine.js - 9 core workflow methods

#### Workflows to Test (2)
1. âœ… Software ATP Flow (Orange Path): BO â†’ SME â†’ Head NOC
2. âœ… Hardware ATP Flow (Green Path): FOP_RTS â†’ Region_Team â†’ RTH

#### Features to Test (8)
1. âœ… Role-Based Access Control
2. âœ… SLA Management (48h/48h/24h deadlines)
3. âœ… Punchlist System (None/Minor-Major/Critical)
4. âœ… Audit Trail
5. âœ… Review Statistics Dashboard
6. âœ… Evidence Photo Linking
7. âœ… Before/After Evidence Upload
8. âœ… Severity-Based Prioritization

---

## ðŸš€ STEP-BY-STEP EXECUTION PLAN

### âœ… STEP 1: Test Data Preparation (FOUNDATION)

**Objective**: Create test users and data that match ATP_PROCESS_USERS.md

**Tasks**:
1. Create SQL script to insert test users
2. Create test sites (minimum 4 sites)
3. Create test ATP templates (software + hardware)
4. Verify test data in database

**Expected Output**:
```
âœ… 11 test users created
âœ… 4 test sites created
âœ… 2 ATP templates ready
âœ… Database verified
```

**Success Criteria**:
- All users can login
- Sites appear in dropdown
- Templates available for selection

---

### âœ… STEP 2: Backend API Tests (LAYER 1)

**Objective**: Test all 7 new API endpoints

**Test Coverage**:

#### 2.1 Pending Reviews API
```
Endpoint: GET /api/v1/atp/reviews/pending?role=BO
Test Cases:
  âœ“ Should return pending reviews for BO role
  âœ“ Should return empty array if no pending reviews
  âœ“ Should filter by role correctly
  âœ“ Should include SLA deadline info
  âœ“ Should handle invalid role parameter
```

#### 2.2 Completed Reviews API
```
Endpoint: GET /api/v1/atp/reviews/completed?role=SME
Test Cases:
  âœ“ Should return completed reviews for SME role
  âœ“ Should include decision history
  âœ“ Should paginate results
  âœ“ Should filter by date range
```

#### 2.3 Review Statistics API
```
Endpoint: GET /api/v1/atp/reviews/stats?role=HEAD_NOC
Test Cases:
  âœ“ Should return pending count
  âœ“ Should return reviewed today count
  âœ“ Should return approved this week count
  âœ“ Should return rejected this week count
  âœ“ Should calculate statistics correctly
```

#### 2.4 Workflow Status API
```
Endpoint: GET /api/v1/atp/:atpId/workflow-status
Test Cases:
  âœ“ Should return current stage
  âœ“ Should return completion percentage
  âœ“ Should return stage history
  âœ“ Should return review status for each stage
  âœ“ Should handle invalid ATP ID
```

#### 2.5 Punchlist Items API
```
Endpoint: GET /api/v1/atp/punchlist/items?atpId=XXX
Test Cases:
  âœ“ Should return punchlist items for ATP
  âœ“ Should include severity info
  âœ“ Should include status (active/completed)
  âœ“ Should filter by severity
  âœ“ Should filter by status
```

#### 2.6 Punchlist Complete API
```
Endpoint: POST /api/v1/atp/punchlist/:punchlistId/complete
Test Cases:
  âœ“ Should complete punchlist item
  âœ“ Should require before/after evidence
  âœ“ Should update punchlist status
  âœ“ Should log completion timestamp
  âœ“ Should handle invalid punchlist ID
```

#### 2.7 SLA Violations API
```
Endpoint: GET /api/v1/atp/sla/violations
Test Cases:
  âœ“ Should return overdue reviews
  âœ“ Should calculate overdue hours
  âœ“ Should include reviewer info
  âœ“ Should sort by overdue severity
  âœ“ Should return empty if no violations
```

**Expected Output**:
```
âœ… 7 API endpoints tested
âœ… 35+ test cases created
âœ… All endpoints functional
âœ… Response formats validated
```

**Success Criteria**:
- All endpoints return 200 OK
- Response schemas match documentation
- Error cases handled correctly

---

### âœ… STEP 3: Workflow Engine Tests (LAYER 2)

**Objective**: Test all 9 core workflow methods

**Test Coverage**:

#### 3.1 Initialize Workflow
```
Method: initializeWorkflow(atpId, atpType)
Test Cases:
  âœ“ Should create review stages for Software ATP
  âœ“ Should create review stages for Hardware ATP
  âœ“ Should set correct SLA deadlines (48h/48h/24h)
  âœ“ Should assign reviewers based on role
  âœ“ Should handle invalid ATP type
```

#### 3.2 Process Review Decision
```
Method: processReviewDecision(atpId, stageId, decision)
Test Cases:
  âœ“ Should approve and move to next stage
  âœ“ Should reject and stop workflow
  âœ“ Should create punchlist for "Approve with Punchlist"
  âœ“ Should update stage status
  âœ“ Should handle invalid decision
```

#### 3.3 Get Pending Reviews
```
Method: getPendingReviews(userRole)
Test Cases:
  âœ“ Should return pending reviews for role
  âœ“ Should include ATP document info
  âœ“ Should include SLA deadline
  âœ“ Should sort by deadline priority
  âœ“ Should return empty if none pending
```

#### 3.4 Get Completed Reviews
```
Method: getCompletedReviews(userRole, limit)
Test Cases:
  âœ“ Should return completed reviews
  âœ“ Should include decision history
  âœ“ Should include reviewer comments
  âœ“ Should paginate correctly
  âœ“ Should filter by date range
```

#### 3.5 Get Review Stats
```
Method: getReviewStats(userRole)
Test Cases:
  âœ“ Should return pending count
  âœ“ Should return reviewed today count
  âœ“ Should return approved this week
  âœ“ Should return rejected this week
  âœ“ Should calculate correctly for all roles
```

#### 3.6 Complete Punchlist Rectification
```
Method: completePunchlistRectification(punchlistId, evidence)
Test Cases:
  âœ“ Should mark punchlist as completed
  âœ“ Should require before/after photos
  âœ“ Should update completion timestamp
  âœ“ Should notify reviewer (if implemented)
  âœ“ Should handle invalid punchlist ID
```

#### 3.7 Get Workflow Status
```
Method: getWorkflowStatus(atpId)
Test Cases:
  âœ“ Should return current stage name
  âœ“ Should return completion percentage
  âœ“ Should return all stage statuses
  âœ“ Should return punchlist count
  âœ“ Should handle invalid ATP ID
```

#### 3.8 Check SLA Violations
```
Method: checkSLAViolations()
Test Cases:
  âœ“ Should detect overdue reviews
  âœ“ Should calculate overdue duration
  âœ“ Should categorize by severity
  âœ“ Should return empty array if no violations
  âœ“ Should handle database errors
```

#### 3.9 Auto-Categorization
```
Method: categorizeATP(document)
Test Cases:
  âœ“ Should categorize as Software (software keywords)
  âœ“ Should categorize as Hardware (hardware keywords)
  âœ“ Should categorize as Combined (both keywords)
  âœ“ Should return confidence score
  âœ“ Should handle empty content
```

**Expected Output**:
```
âœ… 9 workflow methods tested
âœ… 45+ test cases created
âœ… Business logic validated
âœ… Edge cases covered
```

**Success Criteria**:
- All methods execute without errors
- Business rules enforced correctly
- SLA calculations accurate
- State transitions work as expected

---

### âœ… STEP 4: Frontend Component Tests (LAYER 3)

**Objective**: Test all 5 frontend components

**Test Coverage**:

#### 4.1 ATP Submission Component
```
Component: ATPSubmission.tsx
Test Cases:
  âœ“ Should render site selection dropdown
  âœ“ Should render template selection dropdown
  âœ“ Should validate file upload (PDF only)
  âœ“ Should display requirements checklist
  âœ“ Should submit ATP document successfully
  âœ“ Should show success message after submission
  âœ“ Should handle submission errors
```

#### 4.2 Review Dashboard Component
```
Component: ReviewDashboard.tsx
Test Cases:
  âœ“ Should render pending reviews tab
  âœ“ Should render completed reviews tab
  âœ“ Should display review statistics
  âœ“ Should show SLA deadline indicators
  âœ“ Should apply filters correctly
  âœ“ Should search reviews
  âœ“ Should navigate to approval interface
```

#### 4.3 Approval Interface Component
```
Component: ApprovalInterface.tsx
Test Cases:
  âœ“ Should render checklist tab
  âœ“ Should render evidence tab
  âœ“ Should render document tab
  âœ“ Should render history tab
  âœ“ Should allow Pass/Fail/NA evaluation
  âœ“ Should create punchlist items
  âœ“ Should submit approve decision
  âœ“ Should submit reject decision
  âœ“ Should submit "approve with punchlist" decision
```

#### 4.4 Punchlist Management Component
```
Component: PunchlistManagement.tsx
Test Cases:
  âœ“ Should render active punchlist tab
  âœ“ Should render completed punchlist tab
  âœ“ Should display severity indicators
  âœ“ Should allow before evidence upload
  âœ“ Should allow after evidence upload
  âœ“ Should allow rectification notes
  âœ“ Should complete punchlist item
  âœ“ Should filter by severity
```

#### 4.5 ATP Process Flow Component
```
Component: ATPProcessFlow.tsx
Test Cases:
  âœ“ Should switch components based on role
  âœ“ Should navigate between modules
  âœ“ Should enforce role-based access
  âœ“ Should handle unauthorized access
  âœ“ Should display workflow progress
```

**Expected Output**:
```
âœ… 5 components tested
âœ… 35+ test cases created
âœ… UI functionality validated
âœ… User interactions work
```

**Success Criteria**:
- Components render without errors
- User interactions functional
- Navigation works correctly
- Role-based access enforced

---

### âœ… STEP 5: End-to-End User Journey Tests (LAYER 4)

**Objective**: Test complete workflows from user perspective

**Test Coverage**:

#### 5.1 Software ATP Flow (Orange Path) - Happy Path
```
Scenario: Complete Software ATP approval without punchlist
Actors:
  1. Vendor (doc.control@aviat.com)
  2. Business Ops (business.ops@xlsmart.co.id)
  3. SME (sme.team@xlsmart.co.id)
  4. Head NOC (noc.head@xlsmart.co.id)

Steps:
  1. Vendor logs in
  2. Vendor submits Software ATP document
  3. System auto-categorizes as Software
  4. System initializes workflow (BO â†’ SME â†’ Head NOC)
  5. Business Ops reviews and approves
  6. System advances to SME stage
  7. SME reviews and approves
  8. System advances to Head NOC stage
  9. Head NOC reviews and approves
  10. System marks ATP as fully approved

Expected Results:
  âœ“ ATP submitted successfully
  âœ“ Categorized as Software
  âœ“ 3 review stages completed
  âœ“ Final status: approved
  âœ“ No punchlist items
  âœ“ All audit trails preserved
```

#### 5.2 Software ATP Flow - With Punchlist
```
Scenario: Software ATP approval with minor punchlist
Actors: Same as 5.1

Steps:
  1-4. Same as 5.1
  5. Business Ops reviews and approves
  6. SME reviews, finds 2 issues
  7. SME creates 2 punchlist items (1 Major, 1 Minor)
  8. SME selects "Approve with Punchlist"
  9. System advances to Head NOC (with punchlist)
  10. Head NOC reviews punchlist items
  11. Head NOC approves with punchlist
  12. System marks ATP as approved with punchlist

Expected Results:
  âœ“ ATP approved with punchlist
  âœ“ 2 punchlist items created
  âœ“ Severity levels correct
  âœ“ Punchlist status: active
  âœ“ Vendor can see punchlist items
```

#### 5.3 Software ATP Flow - Rejection
```
Scenario: Software ATP rejection at BO stage
Actors:
  1. Vendor (doc.control@aviat.com)
  2. Business Ops (business.ops@xlsmart.co.id)

Steps:
  1. Vendor submits Software ATP
  2. Business Ops reviews
  3. Business Ops finds critical issues
  4. Business Ops selects "Reject"
  5. Business Ops adds rejection comments
  6. System stops workflow
  7. System marks ATP as rejected

Expected Results:
  âœ“ ATP rejected
  âœ“ Workflow stopped
  âœ“ No further stages created
  âœ“ Vendor notified of rejection
  âœ“ Rejection reason saved
```

#### 5.4 Hardware ATP Flow (Green Path) - Happy Path
```
Scenario: Complete Hardware ATP approval without punchlist
Actors:
  1. Vendor (doc.control@aviat.com)
  2. FOP RTS (fop.rts@xlsmart.co.id)
  3. Region Team (region.team@xlsmart.co.id)
  4. RTH (rth.head@xlsmart.co.id)

Steps:
  1. Vendor logs in
  2. Vendor submits Hardware ATP document
  3. System auto-categorizes as Hardware
  4. System initializes workflow (FOP_RTS â†’ REGION_TEAM â†’ RTH)
  5. FOP RTS reviews and approves
  6. System advances to Region Team stage
  7. Region Team reviews and approves
  8. System advances to RTH stage
  9. RTH reviews and approves
  10. System marks ATP as fully approved

Expected Results:
  âœ“ ATP submitted successfully
  âœ“ Categorized as Hardware
  âœ“ 3 review stages completed
  âœ“ Final status: approved
  âœ“ No punchlist items
```

#### 5.5 Hardware ATP Flow - With Critical Punchlist
```
Scenario: Hardware ATP with critical punchlist requiring rectification
Actors:
  1. Vendor (doc.control@aviat.com)
  2. FOP RTS (fop.rts@xlsmart.co.id)
  3. Region Team (region.team@xlsmart.co.id)
  4. RTH (rth.head@xlsmart.co.id)
  5. Field Engineer (admin@aviat.com)

Steps:
  1-4. Same as 5.4
  5. FOP RTS reviews, finds critical issue
  6. FOP RTS creates punchlist item (severity: Critical)
  7. FOP RTS selects "Approve with Punchlist"
  8. System advances to Region Team
  9. Region Team and RTH approve
  10. ATP approved with critical punchlist
  11. Field Engineer accesses punchlist
  12. Field Engineer uploads before evidence
  13. Field Engineer performs rectification
  14. Field Engineer uploads after evidence
  15. Field Engineer marks punchlist as complete

Expected Results:
  âœ“ Critical punchlist created
  âœ“ Mandatory rectification enforced
  âœ“ Before/after evidence uploaded
  âœ“ Punchlist marked as complete
  âœ“ Audit trail complete
```

#### 5.6 SLA Violation Detection
```
Scenario: Detect and report SLA violations
Actors: System (automated)

Steps:
  1. Create ATP document
  2. Initialize workflow
  3. Modify database: set submission date to 3 days ago
  4. Call SLA violations endpoint
  5. Verify overdue reviews detected

Expected Results:
  âœ“ System detects overdue review
  âœ“ Calculates overdue hours correctly
  âœ“ Returns in violations endpoint
  âœ“ Flags with high priority
  âœ“ Can be filtered by role
```

**Expected Output**:
```
âœ… 6 E2E scenarios tested
âœ… Complete workflows validated
âœ… All user roles tested
âœ… Business rules enforced
```

**Success Criteria**:
- All scenarios complete successfully
- No console errors
- Database state correct
- UI displays expected results

---

## ðŸ“Š TEST EXECUTION ORDER

### Week 1: Foundation
```
Day 1-2: STEP 1 - Test Data Preparation
Day 3-4: STEP 2 - Backend API Tests
Day 5:   STEP 3 - Workflow Engine Tests (part 1)
```

### Week 2: Core Testing
```
Day 1-2: STEP 3 - Workflow Engine Tests (part 2)
Day 3-4: STEP 4 - Frontend Component Tests
Day 5:   STEP 5 - E2E Tests (part 1)
```

### Week 3: Integration
```
Day 1-3: STEP 5 - E2E Tests (part 2)
Day 4-5: Bug fixes and regression testing
```

---

## ðŸ“ˆ SUCCESS METRICS

### Coverage Targets
- âœ… Backend API: 100% (7/7 endpoints)
- âœ… Workflow Engine: 100% (9/9 methods)
- âœ… Frontend Components: 100% (5/5 components)
- âœ… E2E Scenarios: 100% (6/6 scenarios)

### Quality Targets
- âœ… All tests pass (100%)
- âœ… Zero critical bugs
- âœ… Zero console errors
- âœ… Code coverage > 80%

---

## âœ… CHECKPOINTS

### Checkpoint 1: After STEP 1
```
âœ… Test users created and verified
âœ… Test sites available
âœ… Can login with all test users
âœ… Database ready
```

### Checkpoint 2: After STEP 2
```
âœ… All 7 API endpoints functional
âœ… API tests passing
âœ… Response schemas validated
âœ… Error handling verified
```

### Checkpoint 3: After STEP 3
```
âœ… All workflow methods tested
âœ… Business logic validated
âœ… SLA calculations accurate
âœ… State transitions working
```

### Checkpoint 4: After STEP 4
```
âœ… All components functional
âœ… UI interactions working
âœ… Role-based access enforced
âœ… Navigation correct
```

### Checkpoint 5: After STEP 5
```
âœ… All E2E scenarios passing
âœ… Complete workflows validated
âœ… Ready for production
```

---

## ðŸš€ NEXT STEP

**Ready to start STEP 1: Test Data Preparation**

This will involve:
1. Creating SQL script for test users (matching ATP_PROCESS_USERS.md)
2. Creating test sites
3. Creating test ATP templates
4. Verifying database state

**Shall I proceed with STEP 1?**

---

**Plan Date**: 2025-12-28
**Status**: Ready for Execution
**Estimated Duration**: 3 weeks (complete)
**First Step Duration**: 1-2 days (test data prep)
